{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from kymatio import Scattering2D\n",
    "from phase_scattering2d_torch import ScatteringTorch2D_wph\n",
    "from models.ISTC import ISTC, relu\n",
    "from models.Rescaling import Rescaling\n",
    "from models.LinearProj import LinearProj\n",
    "from models.Classifier import Classifier\n",
    "from models.SparseScatNet import SparseScatNet\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import print_and_write, compute_stding_matrix\n",
    "\n",
    "import math\n",
    "import numpy as np \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.figsize\"] = (16,9)\n",
    "mpl.rcParams[\"axes.titlesize\"] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder to save all the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\r\n",
      "README.md\r\n",
      "__pycache__\r\n",
      "checkpoints\r\n",
      "checkpoints_sparsescatnet\r\n",
      "checkpoints_sparsescatnet_100_class\r\n",
      "checkpoints_sparsescatnet_100_class_dict_save\r\n",
      "checkpoints_sparsescatnet_10_class\r\n",
      "checkpoints_sparsescatnet_16\r\n",
      "checkpoints_sparsescatnet_30_class\r\n",
      "cmd.txt\r\n",
      "convergence_analysis.ipynb\r\n",
      "convergence_analysis.py\r\n",
      "main.py\r\n",
      "model_analysis.ipynb\r\n",
      "models\r\n",
      "phase_scattering2d_torch.py\r\n",
      "plots\r\n",
      "run_from_cluster.ipynb\r\n",
      "sparsescatnet_logs\r\n",
      "sparsescatnet_logs_100_class\r\n",
      "sparsescatnet_logs_100_class_dict_save\r\n",
      "sparsescatnet_logs_10_class\r\n",
      "sparsescatnet_logs_16\r\n",
      "sparsescatnet_logs_30_class\r\n",
      "standardization\r\n",
      "training_logs\r\n",
      "utils.py\r\n",
      "utils_sampling\r\n"
     ]
    }
   ],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_indices_selected\r\n",
      "events.out.tfevents.1614865438.sh15.2266.0\r\n",
      "events.out.tfevents.1614865650.sh15.2634.0\r\n",
      "events.out.tfevents.1614865864.sh15.2942.0\r\n",
      "events.out.tfevents.1614941404.sh15.24593.0\r\n",
      "events.out.tfevents.1615398692.sh04.29827.0\r\n",
      "summary_file.txt\r\n",
      "training_sparsescatnet_b_256_lrfreq_60.log\r\n"
     ]
    }
   ],
   "source": [
    "! ls sparsescatnet_logs_100_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsescatnet_batchsize_256_lrfreq_60.pth.tar\r\n",
      "sparsescatnet_batchsize_256_lrfreq_60_best.pth.tar\r\n"
     ]
    }
   ],
   "source": [
    "! ls checkpoints_sparsescatnet_100_class/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"checkpoints_sparsescatnet_100_class/sparsescatnet_batchsize_256_lrfreq_60_best.pth.tar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyse the saved model with image size equals to 100 and for which we used 100 classes for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'arch', 'state_dict', 'best_acc1', 'optimizer'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'param_groups'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict[\"optimizer\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = loaded_dict[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['module.scattering.0.tensor0', 'module.scattering.0.tensor1', 'module.scattering.0.tensor2', 'module.scattering.0.tensor3', 'module.scattering.0.tensor4', 'module.scattering.0.tensor5', 'module.scattering.0.tensor6', 'module.scattering.0.tensor7', 'module.scattering.0.tensor8', 'module.scattering.0.tensor9', 'module.scattering.0.tensor10', 'module.scattering.0.tensor11', 'module.scattering.0.tensor12', 'module.scattering.0.tensor13', 'module.scattering.0.tensor14', 'module.scattering.0.tensor15', 'module.scattering.0.tensor16', 'module.scattering.0.tensor17', 'module.scattering.0.tensor18', 'module.scattering.0.tensor19', 'module.scattering.0.tensor20', 'module.scattering.0.tensor21', 'module.scattering.0.tensor22', 'module.scattering.0.tensor23', 'module.scattering.0.tensor24', 'module.scattering.0.tensor25', 'module.scattering.0.tensor26', 'module.scattering.0.tensor27', 'module.scattering.0.tensor28', 'module.scattering.0.tensor29', 'module.scattering.0.tensor30', 'module.scattering.0.tensor31', 'module.scattering.0.tensor32', 'module.scattering.0.tensor33', 'module.scattering.0.tensor34', 'module.scattering.0.tensor35', 'module.scattering.0.tensor36', 'module.scattering.0.tensor37', 'module.scattering.0.tensor38', 'module.scattering.0.tensor39', 'module.scattering.0.tensor40', 'module.scattering.0.tensor41', 'module.scattering.0.tensor42', 'module.scattering.0.tensor43', 'module.scattering.0.tensor44', 'module.scattering.0.tensor45', 'module.scattering.0.tensor46', 'module.scattering.0.tensor47', 'module.scattering.0.tensor48', 'module.scattering.0.tensor49', 'module.scattering.0.tensor50', 'module.scattering.0.tensor51', 'module.scattering.0.tensor52', 'module.scattering.0.tensor53', 'module.scattering.0.tensor54', 'module.scattering.0.tensor55', 'module.scattering.0.tensor56', 'module.scattering.0.tensor57', 'module.scattering.0.tensor58', 'module.scattering.0.tensor59', 'module.scattering.0.tensor60', 'module.scattering.0.tensor61', 'module.scattering.0.tensor62', 'module.scattering.0.tensor63', 'module.scattering.0.tensor64', 'module.scattering.0.tensor65', 'module.scattering.0.tensor66', 'module.scattering.0.tensor67', 'module.scattering.0.tensor68', 'module.scattering.0.tensor69', 'module.scattering.0.tensor70', 'module.scattering.0.tensor71', 'module.scattering.0.tensor72', 'module.scattering.0.tensor73', 'module.scattering.0.tensor74', 'module.scattering.0.tensor75', 'module.linear_proj.standardization.bias', 'module.linear_proj.standardization.scaling_mat', 'module.linear_proj.proj.weight', 'module.istc.dictionary_weight', 'module.istc.w_weight', 'module.istc.log_lambda_0', 'module.istc.log_lambdas', 'module.istc.log_lambda_star', 'module.istc.log_gamma', 'module.istc.lambda_0', 'module.istc.lambdas', 'module.istc.lambda_star', 'module.istc.gamma', 'module.classifier.bn.weight', 'module.classifier.bn.bias', 'module.classifier.bn.running_mean', 'module.classifier.bn.running_var', 'module.classifier.bn.num_batches_tracked', 'module.classifier.classifier.0.weight', 'module.classifier.classifier.0.bias', 'module.classifier.classifier.3.weight', 'module.classifier.classifier.3.bias', 'module.classifier.classifier.6.weight', 'module.classifier.classifier.6.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict[\"state_dict\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the args used to train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['sparsescatnet', 'sparsescatnetw', 'scatnet']\n",
    "\n",
    "NEW_IMAGE_SIZE = 100\n",
    "\n",
    "arch               = \"sparsescatnet\"\n",
    "scattering_J       = 4\n",
    "scattering_order2  = True\n",
    "scat_angles        = 8\n",
    "scattering_wph     = True\n",
    "scattering_nphases = 4\n",
    "nb_classes         = 100\n",
    "L_proj_size        = 256\n",
    "L_kernel_size      = 3\n",
    "n_iterations       = 12\n",
    "dictionary_size    = 2048\n",
    "classifier_type    = \"mlp\"\n",
    "lambda_0           = 0.3\n",
    "lambda_star        = 0.05\n",
    "lambda_star_lb     = 0.05\n",
    "grad_lambda_star   = True\n",
    "epsilon_lambda_0   = 1\n",
    "output_rec         = False\n",
    "nb_hidden_units    = 4096\n",
    "nb_l_mlp           = 2\n",
    "dropout_p_mlp      = 0.3\n",
    "avg_ker_size       = 3\n",
    "BS                 = 256\n",
    "workers            = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch in model_names:\n",
    "    n_space = NEW_IMAGE_SIZE\n",
    "    nb_channels_in = 3\n",
    "\n",
    "    # create scattering\n",
    "    J = scattering_J\n",
    "    L_ang = scat_angles\n",
    "\n",
    "    max_order = 2 if scattering_order2 else 1\n",
    "\n",
    "    if scattering_wph:\n",
    "        A = scattering_nphases\n",
    "        scattering = ScatteringTorch2D_wph(J=J, shape=(NEW_IMAGE_SIZE, NEW_IMAGE_SIZE), L=L_ang, A=A, \n",
    "                                           max_order=max_order)                                    \n",
    "    else:\n",
    "        scattering = Scattering2D(J=J, shape=(NEW_IMAGE_SIZE, NEW_IMAGE_SIZE), L=L_ang, \n",
    "                                  max_order=max_order)\n",
    "    # Flatten scattering\n",
    "    scattering = nn.Sequential(scattering, nn.Flatten(1, 2))\n",
    "\n",
    "    if scattering_wph:\n",
    "        nb_channels_in += 3 * A * L_ang * J\n",
    "    else:\n",
    "        nb_channels_in += 3 * L_ang * J\n",
    "\n",
    "    if max_order == 2:\n",
    "        nb_channels_in += 3 * (L_ang ** 2) * J * (J - 1) // 2\n",
    "\n",
    "    n_space = n_space // (2 ** J)\n",
    "###########################################################################################\n",
    "    \n",
    "    std_file = 'standardization/ImageNet2012_scattering_J{}_order{}_wph_{}_nphases_{}_nb_classes_{}.pth.tar'.format(\n",
    "        scattering_J, 2 if scattering_order2 else 1, scattering_wph,\n",
    "        scattering_nphases if scattering_wph else 0, nb_classes)\n",
    "\n",
    "    # compute the mean and the std of the data\n",
    "    if os.path.isfile(std_file):\n",
    "        std_dict = torch.load(std_file)\n",
    "        mean_std = std_dict['mean']\n",
    "        stding_mat = std_dict['matrix']\n",
    "    else:\n",
    "        print(\"standirisation file not found\")\n",
    "\n",
    "    standardization = Rescaling(mean_std, stding_mat)\n",
    "    \n",
    "    if arch in ['sparsescatnet', 'sparsescatnetw']:\n",
    "        proj = nn.Conv2d(nb_channels_in, L_proj_size, kernel_size=L_kernel_size, stride=1,\n",
    "                         padding=0, bias=False)\n",
    "        nb_channels_in = L_proj_size\n",
    "        linear_proj = LinearProj(standardization, proj, L_kernel_size)\n",
    "    else:  # scatnet\n",
    "        proj = nn.Identity()\n",
    "        linear_proj = LinearProj(standardization, proj, 0)\n",
    "\n",
    "    ###########################################################################################\n",
    "\n",
    "    # Create ISTC (when applicable)\n",
    "    if arch in ['sparsescatnet', 'sparsescatnetw']:\n",
    "    ###########################################################################################\n",
    "        if arch == 'sparsescatnet':\n",
    "            istc = ISTC(nb_channels_in, dictionary_size=dictionary_size, n_iterations=n_iterations,\n",
    "                        lambda_0=lambda_0, lambda_star=lambda_star, lambda_star_lb=lambda_star_lb,\n",
    "                        grad_lambda_star=grad_lambda_star, epsilon_lambda_0=epsilon_lambda_0,\n",
    "                        output_rec=output_rec)\n",
    "\n",
    "        elif arch == 'sparsescatnetw':\n",
    "            istc = ISTC(nb_channels_in, dictionary_size=dictionary_size, n_iterations=n_iterations,\n",
    "                        lambda_0=lambda_0, lambda_star=lambda_star, lambda_star_lb=lambda_star_lb,\n",
    "                        grad_lambda_star=grad_lambda_star, epsilon_lambda_0=epsilon_lambda_0,\n",
    "                        output_rec=output_rec, use_W=True)\n",
    "\n",
    "        if not output_rec:\n",
    "            nb_channels_in = dictionary_size\n",
    "\n",
    "    elif arch == 'scatnet':\n",
    "        print(\"=> creating model ScatNet with phase scattering {} and classifier {}\".\\\n",
    "            format(scattering_wph, classifier_type))\n",
    "\n",
    "    # Create classifier\n",
    "    ###########################################################################################\n",
    "    classifier = Classifier(n_space, nb_channels_in, classifier_type=classifier_type,\n",
    "                            nb_classes=1000, nb_hidden_units=nb_hidden_units, nb_l_mlp=nb_l_mlp,\n",
    "                            dropout_p_mlp=dropout_p_mlp, avg_ker_size=avg_ker_size)\n",
    "\n",
    "    # Create model\n",
    "    ###########################################################################################\n",
    "    #model = SparseScatNet(scattering, linear_proj, istc, nn.Identity(), return_full_inf=False)\n",
    "    if arch in ['sparsescatnet', 'sparsescatnetw']:\n",
    "        model = SparseScatNet(scattering, linear_proj, istc, classifier, return_full_inf=True)  # print model info\n",
    "\n",
    "    elif arch == 'scatnet':\n",
    "        model = nn.Sequential(scattering, linear_proj, classifier)\n",
    "else:\n",
    "    print(\"not a valid model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the model using the saved weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = model.state_dict()\n",
    "checkpoint_dict = loaded_dict['state_dict']\n",
    "checkpoint_dict = {k: v for k, v in checkpoint_dict.items() if k in model_dict}\n",
    "model_dict.update(checkpoint_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "dictionary = model.istc.dictionary_weight.data\n",
    "w_matrix   = model.istc.w_weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model to GPU and enable eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseScatNet(\n",
       "  (scattering): Sequential(\n",
       "    (0): ScatteringTorch2D_wph()\n",
       "    (1): Flatten(start_dim=1, end_dim=2)\n",
       "  )\n",
       "  (linear_proj): LinearProj(\n",
       "    (standardization): Rescaling()\n",
       "    (proj): Conv2d(1539, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (istc): ISTC()\n",
       "  (classifier): Classifier(\n",
       "    (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=32768, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.3, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"~/Datasets/ImageNet/ILSVRC/Data/CLS-LOC\"\n",
    "\n",
    "valdir   = os.path.join(path_data, 'val')\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.Resize((NEW_IMAGE_SIZE, NEW_IMAGE_SIZE)),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a subset of the dataset will be analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.Subset(dataset, range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader  = torch.utils.data.DataLoader(dataset, batch_size=BS, shuffle=False, \n",
    "                                      num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have the loader as a iterable list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_loader = next(iter(loader))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 5\n",
    "imgs, labels = next(iter(loader))\n",
    "\n",
    "fig=plt.figure(figsize=(20,5),facecolor='w')\n",
    "for i in range(nsamples):\n",
    "    ax = plt.subplot(1,nsamples, i+1)\n",
    "    plt.imshow(torch.transpose(torch.transpose(imgs[i, :, :, :], 0, 2), 0, 1), vmin=0, vmax=1)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "title_plot = \"examples_ImageNet\"\n",
    "plt.savefig(f\"plots/{title_plot}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 10\n",
    "input_test = iter_loader[0:n_examples].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scattering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.scattering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of 2D inputs data, and for an input tensor $(B,C,N_1,N_2)$, with $J = $scattering_J and $L = $scat_angles and $A = $scattering_nphases, the output tensor has the following dimension :\n",
    "\n",
    "\n",
    "\n",
    "if scattering_order2 == False : \n",
    "$$ (B, C, 1 + LJ + \\frac{L^{2}J(J-1)}{2}, \\frac{N_1}{2^J}, \\frac{N_2}{2^J})  $$\n",
    "\n",
    "if scattering_order2 == True : \n",
    "$$ (B, C, 1 + ALJ + \\frac{L^{2}J(J-1)}{2}, \\frac{N_1}{2^J}, \\frac{N_2}{2^J})  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------\")\n",
    "print(\"variables values : \")\n",
    "print(f\"scattering_order2      = {scattering_order2}\")\n",
    "print(f\"scattering_J       (J) = {scattering_J}\")\n",
    "print(f\"scat_angles        (L) = {scat_angles}\")\n",
    "print(f\"scattering_nphases (A) = {scattering_nphases}\")\n",
    "print(\"-----------------------------\")\n",
    "print(f\"dimension of the inputs  : (B, {input_test[0].size()[0]}, {input_test[0].size()[1]}, {input_test[0].size()[2]})\")\n",
    "print()\n",
    "dim_3 = 1 + 0.5*scattering_J*(scattering_J-1)*scat_angles**2\n",
    "if scattering_order2 : \n",
    "    dim_3 += scattering_nphases*scat_angles*scattering_J\n",
    "else : \n",
    "    dim_3 += scat_angles*scattering_J\n",
    "dim_3 = int(dim_3)\n",
    "print(f\"dimension of the outputs (expected) : (B, {input_test[0].size()[0]}, {dim_3}, {input_test[0].size()[1]//2**scattering_J}, {input_test[0].size()[2]//2**scattering_J})\")\n",
    "print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.scattering[0](input_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of the scattering transform on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scattering_coef(img_array, scat_coef, J, L, A, save = False, path = \"img.png\") :\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7,7)) \n",
    "    \n",
    "    ## plot the image \n",
    "    ax.imshow(img_array, vmin=0, vmax=1)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)   \n",
    "    \n",
    "    ## plot the scattering coefficients\n",
    "    norm = mpl.colors.Normalize(scat_coef.min(), scat_coef.max(), clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=\"magma\")  ## gray\n",
    "    nb_coeffs, window_rows, window_columns = scat_coef.shape\n",
    "    \n",
    "    \n",
    "    ax.axis('off')\n",
    "    offset = 0.1\n",
    "    for row in range(window_rows):\n",
    "        for column in range(window_columns):\n",
    "            ax=fig.add_subplot(window_rows, window_columns, 1 + column + row * window_rows, projection='polar')\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.axis('off')\n",
    "            ax.set_yticklabels([])  # turn off radial tick labels (yticks)\n",
    "            ax.set_xticklabels([])  # turn off degrees\n",
    "            # ax.set_theta_zero_location('N')  # 0° to North\n",
    "            coefficients = scat_coef[:, row, column]\n",
    "            for j in range(J):\n",
    "                for l in range(L):\n",
    "                    coeff = coefficients[l + (J - 1 - j) * L]\n",
    "                    color = mpl.colors.to_hex(mapper.to_rgba(coeff))\n",
    "                    ax.bar(x=(4.5+l) *  np.pi / L,\n",
    "                           height=2*(2**(j-1) / 2**J),\n",
    "                           width=2 * np.pi / L,\n",
    "                           bottom=offset + (2**j / 2**J) ,\n",
    "                           color=color)\n",
    "                    ax.bar(x=(4.5+l+L) * np.pi / L,\n",
    "                           height=2*(2**(j-1) / 2**J),\n",
    "                           width=2 * np.pi / L,\n",
    "                           bottom=offset + (2**j / 2**J) ,\n",
    "                           color=color)\n",
    "    if save : \n",
    "        plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_coefficients = model.scattering[0](input_test).cpu().numpy()\n",
    "\n",
    "## invert colors : \n",
    "scattering_coefficients = -scattering_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## skip the low pass filter \n",
    "scattering_coefficients = scattering_coefficients[:,:,1:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering_coefficients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\" -- NOTE : since the images are in RGB (3 axis), the scattering rings plotted are the mean of the 3 axis !\")\n",
    "\n",
    "imgs, labels = next(iter(loader))\n",
    "\n",
    "nsamples = 5\n",
    "\n",
    "for i in range(nsamples):\n",
    "    title_plot = f\"plots/scattering_output_{i}.png\"\n",
    "    draw_scattering_coef(torch.transpose(torch.transpose(imgs[i, :, :, :], 0, 2), 0, 1),\n",
    "                         scattering_coefficients[i].mean(axis=0), scattering_J, scat_angles, \n",
    "                         scattering_nphases, save=True, path=title_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_scat = model.scattering(input_test.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"flatten is applied to the output of the scattering, thus we will have a tensor of size: (\\\n",
    "{n_examples}, {3*dim_3}, \\\n",
    "{input_test[0].size()[1]//2**scattering_J}, {input_test[0].size()[2]//2**scattering_J})\"\\\n",
    "     )\n",
    "\n",
    "out_scat.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat_stand = model.linear_proj.standardization(out_scat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat_stand.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_out = model.linear_proj(out_scat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this case, the linear projection is done using a conv2D layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linp_p = lin_out.view(-1,L_proj_size)[0,:].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(linp_p, \"-o\")\n",
    "title_plot = \"output of linear projection on one image\"\n",
    "plt.title(title_plot)\n",
    "plt.savefig(f\"plots/{title_plot}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISTC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.istc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istc_out = model.istc(lin_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istc_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.istc.dictionary_weight.size(), lin_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(lin_out.view(10,6,6,256), model.istc.dictionary_weight.view(256, 2048)).view(10,2048,6,6).norm(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istc_out.norm(p=2), lin_out.norm(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istc_arr = istc_out.view(-1,dictionary_size)[0,:].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(istc_arr, \"-o\")\n",
    "title_plot = \"output of ISTC on 1 image\"\n",
    "plt.title(title_plot)\n",
    "plt.savefig(f\"plots/{title_plot}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_scat.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = out_scat.shape[2]  ### 6 for image size == 100\n",
    "if avg_ker_size > 1:\n",
    "    n += -avg_ker_size + 1\n",
    "\n",
    "in_planes = nb_channels_in * (n ** 2)\n",
    "print(f\"The size of the first linear layer in mode.classifier.classifier is equal to {in_planes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_out = model.classifier(istc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the model to the input data (all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, _, sparsity, support_size, support_diff, rec_loss_rel = model(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Computing the sparsity : \n",
    " - sparsity = torch.zeros(n_iterations)\n",
    " - z = relu(z - WT_D_z + WT_x, lambda_i)\n",
    " - for i_iter < n_iterations :\n",
    "     - sparsity[i_iter] = 100 * (z != 0).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sparsity.detach().cpu().numpy(), \"-o\")\n",
    "title_plot = f\"sparsity for {n_iterations} iterations\"\n",
    "plt.title(title_plot)\n",
    "plt.savefig(f\"plots/{title_plot}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to analyse the sparsity of the dictoinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings 2 functions are from the git : j-zarka/SparseScatNet (edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparse_code_FISTA(input_batch, dictionary, lambda_star, maxiter, tol=1e-3):\n",
    "    with torch.no_grad():\n",
    "        L = torch.symeig(torch.mm(dictionary[..., 0, 0].t(), dictionary[..., 0, 0]))[0][-1]\n",
    "        input_size, dict_size = dictionary.size(0), dictionary.size(1)\n",
    "\n",
    "        support_size_FISTA_curve = np.zeros(maxiter)\n",
    "\n",
    "        batch_size, M, N = input_batch.size(0), input_batch.size(2), input_batch.size(3)\n",
    "        x = input_batch.new_zeros(batch_size, dict_size, M, N)\n",
    "        t = 1\n",
    "        y = x.clone()\n",
    "        dictionary = dictionary.cuda()\n",
    "        for i_iter in range(maxiter):\n",
    "            x_old = x.clone()\n",
    "            D_y = nn.functional.conv2d(y, dictionary)\n",
    "            y = y + nn.functional.conv2d(input_batch - D_y, dictionary.transpose(0, 1).contiguous()) / L\n",
    "            x = relu(y, lambda_star / L)\n",
    "            t0 = t\n",
    "            t = (1. + math.sqrt(1. + 4. * t ** 2)) / 2.\n",
    "            y = x + ((t0 - 1.) / t) * (x - x_old)\n",
    "\n",
    "            support_size_FISTA_curve[i_iter] = (x != 0).sum().item()\n",
    "\n",
    "            diff = ((x - x_old).norm(p=2, dim=1) / (x.norm(p=2, dim=1) + 1e-10))\n",
    "\n",
    "            if tol is not None and diff.max() < tol:\n",
    "                support_size_FISTA_curve[i_iter:] = support_size_FISTA_curve[i_iter - 1]\n",
    "                break\n",
    "    return x, support_size_FISTA_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conv_model(model, val_loader, dictionary, w_matrix, override_lambdas=None):\n",
    "    with torch.no_grad():\n",
    "        input_size, dict_size = dictionary.size(0), dictionary.size(1)\n",
    "        \n",
    "        dictionary = dictionary.cuda()\n",
    "        w_matrix = w_matrix.cuda()\n",
    "\n",
    "        if override_lambdas is not None:\n",
    "            n_iterations = len(override_lambdas)\n",
    "        else:\n",
    "            n_iterations = model.istc.n_iterations\n",
    "\n",
    "        loss_curve = np.zeros(n_iterations)\n",
    "        conv = np.zeros(n_iterations)\n",
    "        x_star_norm = np.zeros(1)\n",
    "        support_size_x_star = np.zeros(n_iterations)\n",
    "        support_size_x_star_curve = np.zeros(200)\n",
    "        support_size_model = np.zeros(n_iterations)\n",
    "        support_incl = np.zeros(n_iterations)\n",
    "        support_diff = np.zeros(n_iterations)\n",
    "        \n",
    "        list_x_star =[]\n",
    "\n",
    "        if override_lambdas is not None:\n",
    "            lambdas = override_lambdas\n",
    "        else:\n",
    "            lambdas = torch.zeros(n_iterations)\n",
    "            lambdas[-1] = model.istc.lambda_star\n",
    "            for i in range(n_iterations-1):\n",
    "                lambdas[i] = model.istc.lambdas[i]\n",
    "\n",
    "        for _, (input_batch, target) in enumerate(val_loader):\n",
    "            input_batch = input_batch.cuda()\n",
    "            input_batch = model(input_batch, return_proj=True)\n",
    "            batch_size, M, N = input_batch.size(0), input_batch.size(2), input_batch.size(3)\n",
    "            # Use FISTA to compute the l1 problem solution\n",
    "            x_star, support_size_x_star_batch = compute_sparse_code_FISTA(input_batch, dictionary, lambdas[-1],\n",
    "                                                                          maxiter=200, tol=1e-3)\n",
    "            list_x_star += [x_star[i:i+1] for i in range(x_star.size(0))]  ## save x_star\n",
    "            \n",
    "            x_star_norm += (x_star.norm(p=2) ** 2).sum().item()\n",
    "            support_size_x_star_curve += support_size_x_star_batch\n",
    "\n",
    "            support_size_x_star[:] += (x_star != 0).sum().item()\n",
    "\n",
    "            x = input_batch.new_zeros(batch_size, dict_size, M, N)\n",
    "            \n",
    "\n",
    "            for i_iter in range(n_iterations):\n",
    "                D_x = nn.functional.conv2d(x, dictionary)\n",
    "                x = x + nn.functional.conv2d(input_batch - D_x, w_matrix.transpose(0, 1).contiguous())\n",
    "                x = relu(x, lambdas[i_iter])\n",
    "\n",
    "                rec_error = 0.5*((nn.functional.conv2d(x, dictionary) - input_batch).norm(p=2, dim=1) ** 2).sum().item()\n",
    "                sparsity_loss = (lambdas[-1]*x).norm(p=1, dim=1).sum().item()\n",
    "                loss_curve[i_iter] += rec_error + sparsity_loss\n",
    "                conv[i_iter] += ((x - x_star).norm(p=2) ** 2).sum().item()\n",
    "                support_size_model[i_iter] += (x != 0).sum()\n",
    "                support_incl[i_iter] += (((x != 0) * (x_star != 0)).sum(dim=1) /\n",
    "                                         torch.max(torch.ones(1).cuda(), (x_star != 0).sum(dim=1).type(torch.cuda.FloatTensor))).sum().item()\n",
    "                support_diff[i_iter] += (((x != 0) * (x_star == 0)).sum(dim=1) /\n",
    "                                         torch.max(torch.ones(1).cuda(), (x_star != 0).sum(dim=1).type(torch.cuda.FloatTensor))).sum().item()\n",
    "\n",
    "        support_incl /= (M * N * len(val_loader.dataset))\n",
    "        support_diff /= (M * N * len(val_loader.dataset))\n",
    "        support_size_x_star /= (M * N * len(val_loader.dataset))\n",
    "        support_size_x_star_curve /= (M * N * len(val_loader.dataset))\n",
    "        support_size_model /= (M * N * len(val_loader.dataset))\n",
    "        loss_curve /= (M * N * len(val_loader.dataset))\n",
    "        conv_rel = conv / x_star_norm\n",
    "\n",
    "    return loss_curve, conv_rel, list_x_star, support_incl, support_diff, support_size_x_star, support_size_x_star_curve, \\\n",
    "           support_size_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve, conv_rel, list_x_star, support_incl, support_diff, support_size_x_star, \\\n",
    "support_size_x_star_curve, support_size_model = compute_conv_model(model, loader, dictionary, w_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_x_star = [x.cpu() for x in list_x_star]  ## to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_x_star[0].size(), len(list_x_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test.size(), lin_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(lin_out[0:1].view(-1).detach().cpu(), label = \"output linear projection\")\n",
    "plt.hist(list_x_star[0].view(-1), label = \"sparse code - alpha\")\n",
    "plt.legend()\n",
    "title_plot = \"histogram_output_linear_vs_sparse_code_1\"\n",
    "plt.title(title_plot)\n",
    "plt.savefig(f\"plots/{title_plot}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "sns.distplot(lin_out[0].view(-1).detach().cpu(), label = \"output linear projection\", ax=ax1, color=\"b\")\n",
    "sns.distplot(list_x_star[0].view(-1), label = \"sparse code - alpha\", ax=ax2, color=\"r\")\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "title_plot = \"histogram_output_linear_vs_sparse_code_2\"\n",
    "plt.title(title_plot)\n",
    "plt.savefig(f\"plots/{title_plot}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" ** Linear projection :\\\n",
    "\\n - total number of coefficients : {lin_out[0].detach().cpu().numel()} \\\n",
    "\\n - zero count     : {(lin_out[0].detach().cpu().numel() - lin_out[0].detach().cpu().count_nonzero()).item()} \\\n",
    "\\n - non zero count : {lin_out[0].detach().cpu().count_nonzero().item()} \\\n",
    "\\n - min abs value  : {abs(lin_out[0].detach().cpu()).min()}\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(f\" ** Sparse code :\\\n",
    "\\n - total number of coefficients : {list_x_star[0].numel()} \\\n",
    "\\n - zero count     : {(list_x_star[0].numel() - list_x_star[0].count_nonzero()).item()} \\\n",
    "\\n - non zero count : {list_x_star[0].count_nonzero().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256*6*6, 2048*6*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(conv_rel, \"-o\")\n",
    "title_plot = f\"relative MSE between the optimal sparse code and the one computed using ISTC after {n_iterations} iterations\"\n",
    "plt.title(title_plot)\n",
    "plt.savefig(f\"plots/{title_plot}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, they reach a value of 0.02 for the relative MSE. We think that the difference is due to the number of classes used (we use 100 and they use all the 1000 classes) and we use just a subset of the validation loader."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
