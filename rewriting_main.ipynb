{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from kymatio import Scattering2D\n",
    "from phase_scattering2d_torch import ScatteringTorch2D_wph\n",
    "from models.ISTC import ISTC\n",
    "from models.Rescaling import Rescaling\n",
    "from models.LinearProj import LinearProj\n",
    "from models.Classifier import Classifier\n",
    "from models.SparseScatNet import SparseScatNet\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import print_and_write, compute_stding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['sparsescatnet', 'sparsescatnetw', 'scatnet']\n",
    "\n",
    "arch = 'sparsescatnet' # model archotecture (sparsescatnet | sparsescatnetw | scatnet)\n",
    "workers = 1 #number of data loading workers\n",
    "epochs = 10 #number of total epochs to run\n",
    "start_epoch = 0 #manual epoch number (useful on restarts)\n",
    "batch_size = 256 #mini-batch size (default: 256), this is the total batch size of all GPUs on the current node when using Data Parallel or Distributed Data Parallel\n",
    "lr = 0.01 #initial learning rate\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "print_freq = 10 #print frequency (default: 10)\n",
    "resume = '' #path to latest checkpoint (default: none)\n",
    "evaluate = True #evaluate model on validation set\n",
    "seed = None #seed for initializing training. \n",
    "\n",
    "# Additional training args\n",
    "learning_rate_adjust_frequency = 30 #number of epoch after which learning rate is decayed by 10 (default: 30)\n",
    "logdir = './training_logs' #directory for training logs\n",
    "savedir = './checkpoints' #directory to save checkpoints\n",
    "\n",
    "# Scattering parameters\n",
    "scattering_order2 = True  #Compute order 2 scattering coefficients\n",
    "scattering_wph = True #phase scattering\n",
    "scat_angles =8 #number of orientations for scattering\n",
    "backend = 'torch' #scattering backend\n",
    "scattering_nphases = 4 #number of phases in the first order of the phase harmonic scattering transform\n",
    "scattering_J = 4 #maximum scale for the scattering transform\n",
    "\n",
    "# Linear projection parameters\n",
    "L_proj_size = 256 #dimension of the linear projection\n",
    "L_kernel_size = 3 #kernel size of L\n",
    "\n",
    "# ISTC(W) parameters\n",
    "n_iterations = 12 #number of iterations for ISTC\n",
    "dictionary_size = 2048 #size of the sparse coding dictionary\n",
    "output_rec = False #output reconstruction\n",
    "lambda_0 = 0.3 #lambda_0\n",
    "lambda_star = 0.05 #lambda_star\n",
    "lambda_star_lb = 0.05 #lambda_star lower bound\n",
    "epsilon_lambda_0 =1. #epsilon for lambda_0 adjustment\n",
    "l0_inf_init = True #initialization of lambda_0 as W^Tx inf\n",
    "grad_lambda_star = True #gradient on lambda_star\n",
    "\n",
    "# Classifier parameters\n",
    "avg_ker_size = 1 #size of averaging kernel\n",
    "classifier_type = 'mlp' #classifier type\n",
    "nb_hidden_units = 2048 #number of hidden units for mlp classifier\n",
    "dropout_p_mlp = 0.3 #dropout probability in mlp\n",
    "nb_l_mlp = 2 #number of hidden layers in mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0\n",
    "best_acc5 = 0\n",
    "best_epoch_acc1 = 0\n",
    "best_epoch_acc5 = 0\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_dir = logdir\n",
    "if not os.path.exists(logs_dir):\n",
    "    os.makedirs(logs_dir)\n",
    "\n",
    "checkpoint_savedir = savedir\n",
    "if not os.path.exists(checkpoint_savedir):\n",
    "    os.makedirs(checkpoint_savedir)\n",
    "\n",
    "logfile = os.path.join(logs_dir, 'training_{}_b_{}_lrfreq_{}.log'.format(\n",
    "    arch, batch_size, learning_rate_adjust_frequency))\n",
    "\n",
    "summaryfile = os.path.join(logs_dir, 'summary_file.txt')\n",
    "\n",
    "checkpoint_savefile = os.path.join(checkpoint_savedir, '{}_batchsize_{}_lrfreq_{}.pth.tar'.format(\n",
    "    arch, batch_size, learning_rate_adjust_frequency))\n",
    "\n",
    "best_checkpoint_savefile = os.path.join(checkpoint_savedir,'{}_batchsize_{}_lrfreq_{}_best.pth.tar'.format(\n",
    "                                            arch, batch_size, learning_rate_adjust_frequency))\n",
    "\n",
    "writer = SummaryWriter(logs_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'FashionMNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.path.expanduser(\"~\"), 'Datasets', 'FashionMNIST')\n",
    "valid_ratio = 0.2  # Going to use 80%/20% split for train/valid\n",
    "# normalize = transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "# Load the dataset for the training/validation sets\n",
    "train_valid_dataset = datasets.FashionMNIST(root=dataset_dir,\n",
    "                                        train=True,\n",
    "                                        transform= transforms.Compose([\n",
    "#                                                     transforms.RandomResizedCrop(224),\n",
    "                                                    transforms.RandomHorizontalFlip(),\n",
    "                                                    transforms.ToTensor(),\n",
    "#                                                     normalize\n",
    "                                                ]), \n",
    "                                        download=True)\n",
    "nb_train = int((1.0 - valid_ratio) * len(train_valid_dataset))\n",
    "nb_valid =  int(valid_ratio * len(train_valid_dataset))\n",
    "train_dataset, valid_dataset = torch.utils.data.dataset.random_split(train_valid_dataset, [nb_train, nb_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(train_dataset, np.arange(512))\n",
    "valid_dataset = Subset(valid_dataset, np.arange(512))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=workers, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "nsamples=5\n",
    "classes_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal','Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "imgs, labels = next(iter(train_loader))\n",
    "\n",
    "fig=plt.figure(figsize=(20,5),facecolor='w')\n",
    "for i in range(nsamples):\n",
    "    ax = plt.subplot(1,nsamples, i+1)\n",
    "    plt.imshow(imgs[i, 0, :, :], vmin=0, vmax=1.0, cmap=cm.gray)\n",
    "    ax.set_title(\"{}\".format(classes_names[labels[i]]), fontsize=15)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "print(imgs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_input = imgs.size()[2]\n",
    "size_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes= len(classes_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_scat = imgs[:1,:,:,:]\n",
    "in_scat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_scat = torch.zeros([10, 3, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_channels_init = in_scat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_channels_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scattering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_space = size_input\n",
    "nb_channels_in = nb_channels_init\n",
    "\n",
    "# create scattering\n",
    "J = scattering_J\n",
    "L_ang = scat_angles\n",
    "\n",
    "max_order = 2 if scattering_order2 else 1\n",
    "\n",
    "if scattering_wph:\n",
    "    A = scattering_nphases\n",
    "    scattering = ScatteringTorch2D_wph(J=J, shape=(size_input, size_input), L=L_ang, A=A, max_order=max_order,\n",
    "                                       backend=backend)\n",
    "else:\n",
    "    scattering = Scattering2D(J=J, shape=(size_input, size_input), L=L_ang, max_order=max_order,\n",
    "                              backend=backend)\n",
    "# Flatten scattering\n",
    "scattering = nn.Sequential(scattering, nn.Flatten(1, 2))\n",
    "\n",
    "if scattering_wph:\n",
    "    nb_channels_in += nb_channels_init * A * L_ang * J\n",
    "else:\n",
    "    nb_channels_in += nb_channels_init * L_ang * J\n",
    "\n",
    "if max_order == 2:\n",
    "    nb_channels_in += nb_channels_init * (L_ang ** 2) * J * (J - 1) // 2\n",
    "\n",
    "n_space = n_space // (2 ** J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_channels_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_scat = scattering(in_scat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 33, 1, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_scat.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mean and standardization matrix...\n",
      "Starting by computing mean and std dev...\n",
      "batch: [0/2]\n",
      "Creating stding matrix...\n",
      "=> saving scattering mean and std 'standardization/FashionMNIST_scattering_J4_order1_wph_False_nphases_0_nb_classes_10.pth.tar'\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# create linear proj\n",
    "# Standardization (can also be performed with BatchNorm2d(affine=False))\n",
    "if not os.path.exists('standardization'):\n",
    "    os.makedirs('standardization')\n",
    "std_file = 'standardization/{}_scattering_J{}_order{}_wph_{}_nphases_{}_nb_classes_{}.pth.tar'.format(dataset_name,\n",
    "    scattering_J, 2 if scattering_order2 else 1, scattering_wph,\n",
    "    scattering_nphases if scattering_wph else 0, nb_classes)\n",
    "\n",
    "if os.path.isfile(std_file):\n",
    "    print_and_write(\"=> loading scattering mean and std '{}'\".format(std_file), logfile)\n",
    "    std_dict = torch.load(std_file)\n",
    "    mean_std = std_dict['mean']\n",
    "    stding_mat = std_dict['matrix']\n",
    "else:\n",
    "    mean_std, stding_mat, std = compute_stding_matrix(train_loader, scattering, logfile)\n",
    "    print_and_write(\"=> saving scattering mean and std '{}'\".format(std_file), logfile)\n",
    "    std_dict = {'mean': mean_std, 'std': std, 'matrix': stding_mat}\n",
    "    torch.save(std_dict, std_file)\n",
    "\n",
    "standardization = Rescaling(mean_std, stding_mat)\n",
    "# standardization = nn.BatchNorm2d(nb_channels_in, affine=False)\n",
    "\n",
    "if arch in ['sparsescatnet', 'sparsescatnetw']:\n",
    "    print(nb_channels_in)\n",
    "    proj = nn.Conv2d(nb_channels_in, L_proj_size, kernel_size=L_kernel_size, stride=1,\n",
    "                     padding=0, bias=False)\n",
    "    nb_channels_in = L_proj_size\n",
    "    linear_proj = LinearProj(standardization, proj, L_kernel_size)\n",
    "else:  # scatnet\n",
    "    proj = nn.Identity()\n",
    "    linear_proj = LinearProj(standardization, proj, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 33, 1, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_scat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Argument #6: Padding size should be less than the corresponding input dimension, but got: padding (1, 1) at dimension 2 of input 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-8a0fc68f1dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_scat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pfe_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CentraleSupelec/PFE/SparseScatNet/models/LinearProj.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_kernel_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_kernel_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pfe_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   3568\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4D tensors expect 4 values for padding'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3570\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflection_pad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3571\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'replicate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3572\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplication_pad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Argument #6: Padding size should be less than the corresponding input dimension, but got: padding (1, 1) at dimension 2 of input 4"
     ]
    }
   ],
   "source": [
    "out_proj = linear_proj(out_scat[:,:,0,0])\n",
    "out_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 10, 513])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_proj.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch in ['sparsescatnet', 'sparsescatnetw']:\n",
    "###########################################################################################\n",
    "    if arch == 'sparsescatnet':\n",
    "        arch_log = \"=> creating model SparseScatNet with phase scattering {}, linear projection \" \\\n",
    "                   \"(projection dimension {}), ISTC with {} iterations, dictionary size {}, classifier {} \" \\\n",
    "                   \"pipeline\".format(scattering_wph, L_proj_size, n_iterations,\n",
    "                                     dictionary_size, classifier_type)\n",
    "\n",
    "        istc = ISTC(nb_channels_in, dictionary_size=dictionary_size, n_iterations=n_iterations,\n",
    "                    lambda_0=lambda_0, lambda_star=lambda_star, lambda_star_lb=lambda_star_lb,\n",
    "                    grad_lambda_star=grad_lambda_star, epsilon_lambda_0=epsilon_lambda_0,\n",
    "                    output_rec=output_rec)\n",
    "\n",
    "    elif arch == 'sparsescatnetw':\n",
    "        arch_log = \"=> creating model SparseScatNetW with phase scattering {}, linear projection \" \\\n",
    "                   \"(projection dimension {}), ISTCW with {} iterations, dictionary size {}, classifier {} \" \\\n",
    "                   \"pipeline\".format(scattering_wph, L_proj_size, n_iterations,\n",
    "                                     dictionary_size, classifier_type)\n",
    "\n",
    "        istc = ISTC(nb_channels_in, dictionary_size=dictionary_size, n_iterations=n_iterations,\n",
    "                    lambda_0=lambda_0, lambda_star=lambda_star, lambda_star_lb=lambda_star_lb,\n",
    "                    grad_lambda_star=grad_lambda_star, epsilon_lambda_0=epsilon_lambda_0,\n",
    "                    output_rec=output_rec, use_W=True)\n",
    "\n",
    "    if not output_rec:\n",
    "        nb_channels_in = dictionary_size\n",
    "\n",
    "elif arch == 'scatnet':\n",
    "    arch_log = \"=> creating model ScatNet with phase scattering {} and classifier {}\".\\\n",
    "        format(scattering_wph, classifier_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_istc = istc(out_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 10, 513])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_istc.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(n_space, nb_channels_in, classifier_type=classifier_type,\n",
    "                        nb_classes=nb_classes, nb_hidden_units=nb_hidden_units, nb_l_mlp=nb_l_mlp,\n",
    "                                dropout_p_mlp=dropout_p_mlp, avg_ker_size=avg_ker_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch in ['sparsescatnet', 'sparsescatnetw']:\n",
    "    model = SparseScatNet(scattering, linear_proj, istc, classifier, return_full_inf=True)  # print model info\n",
    "\n",
    "elif arch == 'scatnet':\n",
    "    model = nn.Sequential(scattering, linear_proj, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (1, 1) at dimension 3 of input 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-dd2c49315b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_scat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pfe_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CentraleSupelec/PFE/SparseScatNet/models/SparseScatNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_proj)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_proj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscattering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_proj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pfe_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CentraleSupelec/PFE/SparseScatNet/models/LinearProj.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_kernel_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_kernel_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pfe_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   3568\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4D tensors expect 4 values for padding'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3570\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflection_pad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3571\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'replicate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3572\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplication_pad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (1, 1) at dimension 3 of input 4"
     ]
    }
   ],
   "source": [
    "model(in_scat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('pfe_env': conda)",
   "language": "python",
   "name": "python361264bitpfeenvcondad4470f2c4a5d4f95bd6a7ad1966371a2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
